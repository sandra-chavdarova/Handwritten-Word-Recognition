{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMp/ycSPQeS24G5Ae5iJRq+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1UTbU6PxLu5","executionInfo":{"status":"ok","timestamp":1765831782398,"user_tz":-60,"elapsed":72832,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"e14438b5-f506-4fe0-9fee-c5c41a9d4a81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting idx2numpy\n","  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from idx2numpy) (2.0.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from idx2numpy) (1.17.0)\n","Building wheels for collected packages: idx2numpy\n","  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7903 sha256=e3728ad850fdbc0a643a5b38167d900cf54f4ca01654efb06da281437687bd3c\n","  Stored in directory: /root/.cache/pip/wheels/f7/48/00/ae031c97d62f39e1c3c4daa00426c09a65eb29ae5753a189ee\n","Successfully built idx2numpy\n","Installing collected packages: idx2numpy\n","Successfully installed idx2numpy-1.2.3\n","Mounted at /content/drive\n","Device: cuda\n"]}],"source":["!pip install idx2numpy\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)"]},{"cell_type":"code","source":["def accuracy_from_logits(logits, targets):\n","    preds = logits.argmax(dim=1)\n","    correct = (preds == targets).sum().item()\n","    total = targets.size(0)\n","    return correct / total\n","\n","def train_one_epoch(model, loader, optimizer, criterion, device):\n","    model.train()\n","    running_loss = 0.0\n","    running_acc  = 0.0\n","    total_batches = 0\n","\n","    for images, labels in loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        running_acc  += accuracy_from_logits(outputs, labels)\n","        total_batches += 1\n","\n","    return running_loss / total_batches, running_acc / total_batches\n","\n","def eval_model(model, loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    running_acc  = 0.0\n","    total_batches = 0\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item()\n","            running_acc  += accuracy_from_logits(outputs, labels)\n","            total_batches += 1\n","\n","    return running_loss / total_batches, running_acc / total_batches\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.pool  = nn.MaxPool2d(2, 2)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.fc1   = nn.Linear(128 * 7 * 7, 256)\n","        self.fc2   = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = F.relu(self.conv3(x))\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n"],"metadata":{"id":"ZGzoBlf-xtqb","executionInfo":{"status":"ok","timestamp":1765831860537,"user_tz":-60,"elapsed":57,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ---------- MNIST ----------\n","import idx2numpy\n","\n","MNIST_DIR = \"/content/drive/MyDrive/AIProject/numbers\"\n","train_images_path = f\"{MNIST_DIR}/train-images.idx3-ubyte\"\n","train_labels_path = f\"{MNIST_DIR}/train-labels.idx1-ubyte\"\n","test_images_path  = f\"{MNIST_DIR}/t10k-images.idx3-ubyte\"\n","test_labels_path  = f\"{MNIST_DIR}/t10k-labels.idx1-ubyte\"\n","\n","X_mnist_train = idx2numpy.convert_from_file(train_images_path)\n","y_mnist_train = idx2numpy.convert_from_file(train_labels_path)\n","X_mnist_test  = idx2numpy.convert_from_file(test_images_path)\n","y_mnist_test  = idx2numpy.convert_from_file(test_labels_path)\n","\n","X_mnist_train = X_mnist_train.astype(np.float32) / 255.0\n","X_mnist_test  = X_mnist_test.astype(np.float32)  / 255.0"],"metadata":{"id":"IX2WkmhGxR6F","executionInfo":{"status":"ok","timestamp":1765831861467,"user_tz":-60,"elapsed":141,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# add channel dim: (N,28,28) -> (N,1,28,28)\n","if X_mnist_train.ndim == 3:\n","    X_mnist_train = X_mnist_train[:, None, :, :]\n","if X_mnist_test.ndim == 3:\n","    X_mnist_test  = X_mnist_test[:, None, :, :]\n","\n","print(\"MNIST shapes:\", X_mnist_train.shape, X_mnist_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a01r5kSsxbs8","executionInfo":{"status":"ok","timestamp":1765831862273,"user_tz":-60,"elapsed":9,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"7b387d8b-cd11-41c9-cd5c-21438cc03fc6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["MNIST shapes: (60000, 1, 28, 28) (10000, 1, 28, 28)\n"]}]},{"cell_type":"code","source":["# ---------- A_Z letters ----------\n","AZ_DIR = \"/content/drive/MyDrive/AIProject/letters kaggle\"\n","AZ_CSV = f\"{AZ_DIR}/A_Z Handwritten Data.csv\"\n","az_df = pd.read_csv(AZ_CSV, header=None)\n","\n","y_az = az_df.iloc[:, 0].values.astype(np.int64)       # 0–25 for A–Z\n","X_az = az_df.iloc[:, 1:].values.astype(np.float32)    # pixels\n","\n","X_az /= 255.0\n","X_az = X_az.reshape(-1, 1, 28, 28)\n","\n","print(\"A_Z shapes:\", X_az.shape, y_az.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kxf5e4HExndI","executionInfo":{"status":"ok","timestamp":1765831887717,"user_tz":-60,"elapsed":24669,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"323ed97d-5525-4de5-f872-4559e0c20f86"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["A_Z shapes: (372451, 1, 28, 28) (372451,)\n"]}]},{"cell_type":"code","source":["# ---------- DIGIT MODEL (0–9) ----------\n","\n","# use all MNIST digits\n","X_digits = np.concatenate([X_mnist_train, X_mnist_test], axis=0)\n","y_digits = np.concatenate([y_mnist_train, y_mnist_test], axis=0)  # already 0–9\n","\n","X_digits_tensor = torch.from_numpy(X_digits)\n","y_digits_tensor = torch.from_numpy(y_digits)\n","\n","digit_dataset = TensorDataset(X_digits_tensor, y_digits_tensor)\n","\n","total_len = len(digit_dataset)\n","train_len = int(0.8 * total_len)\n","val_len   = int(0.1 * total_len)\n","test_len  = total_len - train_len - val_len\n","\n","digit_train_ds, digit_val_ds, digit_test_ds = random_split(\n","    digit_dataset, [train_len, val_len, test_len],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","\n","BATCH_SIZE = 128\n","digit_train_dl = DataLoader(digit_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","digit_val_dl   = DataLoader(digit_val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n","digit_test_dl  = DataLoader(digit_test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n","\n","digit_model = SimpleCNN(num_classes=10).to(device)\n","digit_criterion = nn.CrossEntropyLoss()\n","digit_optimizer = torch.optim.Adam(digit_model.parameters(), lr=1e-3)\n","\n","EPOCHS = 15\n","for epoch in range(1, EPOCHS + 1):\n","    train_loss, train_acc = train_one_epoch(digit_model, digit_train_dl, digit_optimizer, digit_criterion, device)\n","    val_loss, val_acc     = eval_model(digit_model, digit_val_dl, digit_criterion, device)\n","    print(\n","        f\"[DIGITS] Epoch {epoch:02d}: \"\n","        f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n","        f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\"\n","    )\n","\n","test_loss, test_acc = eval_model(digit_model, digit_test_dl, digit_criterion, device)\n","print(f\"[DIGITS] Test loss={test_loss:.4f}, test acc={test_acc*100:.2f}%\")\n","\n","DIGIT_MODEL_PATH = \"/content/drive/MyDrive/AIProject/digit_cnn_10cls.pth\"\n","torch.save(digit_model.state_dict(), DIGIT_MODEL_PATH)\n","print(\"Saved digit model to:\", DIGIT_MODEL_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5EXFNrrxwgk","executionInfo":{"status":"ok","timestamp":1765831938411,"user_tz":-60,"elapsed":48709,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"e23c0e2c-5b07-46f1-b72c-afa409def84c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[DIGITS] Epoch 01: train_loss=0.1932, train_acc=94.09% | val_loss=0.0791, val_acc=97.61%\n","[DIGITS] Epoch 02: train_loss=0.0464, train_acc=98.56% | val_loss=0.0443, val_acc=98.60%\n","[DIGITS] Epoch 03: train_loss=0.0306, train_acc=99.05% | val_loss=0.0471, val_acc=98.52%\n","[DIGITS] Epoch 04: train_loss=0.0237, train_acc=99.25% | val_loss=0.0371, val_acc=98.86%\n","[DIGITS] Epoch 05: train_loss=0.0188, train_acc=99.39% | val_loss=0.0309, val_acc=99.06%\n","[DIGITS] Epoch 06: train_loss=0.0150, train_acc=99.54% | val_loss=0.0356, val_acc=99.02%\n","[DIGITS] Epoch 07: train_loss=0.0128, train_acc=99.59% | val_loss=0.0371, val_acc=98.99%\n","[DIGITS] Epoch 08: train_loss=0.0104, train_acc=99.66% | val_loss=0.0310, val_acc=99.09%\n","[DIGITS] Epoch 09: train_loss=0.0093, train_acc=99.70% | val_loss=0.0364, val_acc=99.07%\n","[DIGITS] Epoch 10: train_loss=0.0070, train_acc=99.76% | val_loss=0.0376, val_acc=98.96%\n","[DIGITS] Epoch 11: train_loss=0.0064, train_acc=99.79% | val_loss=0.0373, val_acc=99.13%\n","[DIGITS] Epoch 12: train_loss=0.0065, train_acc=99.80% | val_loss=0.0326, val_acc=99.25%\n","[DIGITS] Epoch 13: train_loss=0.0049, train_acc=99.87% | val_loss=0.0421, val_acc=99.00%\n","[DIGITS] Epoch 14: train_loss=0.0066, train_acc=99.79% | val_loss=0.0352, val_acc=99.15%\n","[DIGITS] Epoch 15: train_loss=0.0045, train_acc=99.83% | val_loss=0.0405, val_acc=99.09%\n","[DIGITS] Test loss=0.0477, test acc=99.08%\n","Saved digit model to: /content/drive/MyDrive/AIProject/digit_cnn_10cls.pth\n"]}]},{"cell_type":"code","source":["# ---------- LETTER MODEL (A–Z) ----------\n","\n","# labels y_az are 0–25; use them directly\n","X_letters_tensor = torch.from_numpy(X_az)\n","y_letters_tensor = torch.from_numpy(y_az)\n","\n","letter_dataset = TensorDataset(X_letters_tensor, y_letters_tensor)\n","\n","total_len = len(letter_dataset)\n","train_len = int(0.8 * total_len)\n","val_len   = int(0.1 * total_len)\n","test_len  = total_len - train_len - val_len\n","\n","letter_train_ds, letter_val_ds, letter_test_ds = random_split(\n","    letter_dataset, [train_len, val_len, test_len],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","\n","letter_train_dl = DataLoader(letter_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","letter_val_dl   = DataLoader(letter_val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n","letter_test_dl  = DataLoader(letter_test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n","\n","letter_model = SimpleCNN(num_classes=26).to(device)\n","letter_criterion = nn.CrossEntropyLoss()\n","letter_optimizer = torch.optim.Adam(letter_model.parameters(), lr=1e-3)\n","\n","EPOCHS = 15\n","for epoch in range(1, EPOCHS + 1):\n","    train_loss, train_acc = train_one_epoch(letter_model, letter_train_dl, letter_optimizer, letter_criterion, device)\n","    val_loss, val_acc     = eval_model(letter_model, letter_val_dl, letter_criterion, device)\n","    print(\n","        f\"[LETTERS] Epoch {epoch:02d}: \"\n","        f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n","        f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\"\n","    )\n","\n","test_loss, test_acc = eval_model(letter_model, letter_test_dl, letter_criterion, device)\n","print(f\"[LETTERS] Test loss={test_loss:.4f}, test acc={test_acc*100:.2f}%\")\n","\n","LETTER_MODEL_PATH = \"/content/drive/MyDrive/AIProject/letter_cnn_26cls.pth\"\n","torch.save(letter_model.state_dict(), LETTER_MODEL_PATH)\n","print(\"Saved letter model to:\", LETTER_MODEL_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWHLOFGsx1Ov","executionInfo":{"status":"ok","timestamp":1765832211593,"user_tz":-60,"elapsed":267401,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"312bd575-903a-4220-ab24-e65f08f2c7d0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[LETTERS] Epoch 01: train_loss=0.1367, train_acc=96.12% | val_loss=0.0518, val_acc=98.54%\n","[LETTERS] Epoch 02: train_loss=0.0461, train_acc=98.68% | val_loss=0.0399, val_acc=98.88%\n","[LETTERS] Epoch 03: train_loss=0.0321, train_acc=99.03% | val_loss=0.0369, val_acc=98.97%\n","[LETTERS] Epoch 04: train_loss=0.0219, train_acc=99.30% | val_loss=0.0304, val_acc=99.23%\n","[LETTERS] Epoch 05: train_loss=0.0165, train_acc=99.46% | val_loss=0.0332, val_acc=99.10%\n","[LETTERS] Epoch 06: train_loss=0.0133, train_acc=99.56% | val_loss=0.0282, val_acc=99.29%\n","[LETTERS] Epoch 07: train_loss=0.0102, train_acc=99.67% | val_loss=0.0272, val_acc=99.33%\n","[LETTERS] Epoch 08: train_loss=0.0087, train_acc=99.72% | val_loss=0.0308, val_acc=99.35%\n","[LETTERS] Epoch 09: train_loss=0.0076, train_acc=99.75% | val_loss=0.0291, val_acc=99.37%\n","[LETTERS] Epoch 10: train_loss=0.0071, train_acc=99.77% | val_loss=0.0272, val_acc=99.48%\n","[LETTERS] Epoch 11: train_loss=0.0060, train_acc=99.80% | val_loss=0.0318, val_acc=99.41%\n","[LETTERS] Epoch 12: train_loss=0.0060, train_acc=99.82% | val_loss=0.0276, val_acc=99.45%\n","[LETTERS] Epoch 13: train_loss=0.0053, train_acc=99.83% | val_loss=0.0407, val_acc=99.29%\n","[LETTERS] Epoch 14: train_loss=0.0056, train_acc=99.83% | val_loss=0.0392, val_acc=99.29%\n","[LETTERS] Epoch 15: train_loss=0.0046, train_acc=99.86% | val_loss=0.0278, val_acc=99.58%\n","[LETTERS] Test loss=0.0332, test acc=99.51%\n","Saved letter model to: /content/drive/MyDrive/AIProject/letter_cnn_26cls.pth\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Xj2rMT5OySZY"},"execution_count":null,"outputs":[]}]}