{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOCaHJpFTkH2xwHrldynwNT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5iFejDOw0es_","executionInfo":{"status":"ok","timestamp":1766235810885,"user_tz":-60,"elapsed":5578,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"991acb78-6661-479c-c533-dbe2185c91b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: idx2numpy in /usr/local/lib/python3.12/dist-packages (1.2.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from idx2numpy) (2.0.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from idx2numpy) (1.17.0)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Device: cuda\n"]}],"source":["!pip install idx2numpy\n","import os\n","import numpy as np\n","import pandas as pd\n","import idx2numpy\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)"]},{"cell_type":"code","source":["BASE_DIR = \"/content/drive/MyDrive/AIProject\"\n","\n","DIGIT_MODEL_PATH_CNN = f\"{BASE_DIR}/digit_cnn_10cls.pth\"\n","LETTER_MODEL_PATH_CNN = f\"{BASE_DIR}/letter_cnn_26cls.pth\"\n","\n","DIGIT_MODEL_PATH_LSTM = f\"{BASE_DIR}/digit_lstm_10cls.pth\"\n","LETTER_MODEL_PATH_LSTM = f\"{BASE_DIR}/letter_lstm_26cls.pth\"\n"],"metadata":{"id":"m1jc4Ftt1w5c","executionInfo":{"status":"ok","timestamp":1766237754087,"user_tz":-60,"elapsed":10,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def accuracy_from_logits(logits, targets):\n","    preds = logits.argmax(dim=1)\n","    correct = (preds == targets).sum().item()\n","    total = targets.size(0)\n","    return correct / total\n","\n","\n","def train_one_epoch(model, loader, optimizer, criterion, device):\n","    model.train()\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    total_batches = 0\n","\n","    for images, labels in loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        running_acc += accuracy_from_logits(outputs, labels)\n","        total_batches += 1\n","\n","    return running_loss / total_batches, running_acc / total_batches\n","\n","\n","def eval_model(model, loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    total_batches = 0\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item()\n","            running_acc += accuracy_from_logits(outputs, labels)\n","            total_batches += 1\n","\n","    return running_loss / total_batches, running_acc / total_batches\n"],"metadata":{"id":"8mosh2nQ2AGK","executionInfo":{"status":"ok","timestamp":1766237754966,"user_tz":-60,"elapsed":4,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class SimpleLSTM(nn.Module):\n","    def __init__(self, num_classes, input_size=28, hidden_size=128, num_layers=2, bidirectional=False):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bidirectional = bidirectional\n","        self.num_directions = 2 if bidirectional else 1\n","\n","        self.lstm = nn.LSTM(\n","            input_size=input_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","            bidirectional=bidirectional\n","        )\n","        self.fc = nn.Linear(hidden_size * self.num_directions, num_classes)\n","\n","    def forward(self, x):\n","        # (B, 1, 28, 28) -> (B, 28, 28)\n","        x = x.squeeze(1)                 # remove channel dim -> (B, 28, 28)\n","\n","        out, (h_n, c_n) = self.lstm(x)   # out: (B, seq_len, H*num_directions)\n","\n","        last_out = out[:, -1, :]         # (B, H*num_directions)\n","        logits = self.fc(last_out)       # (B, num_classes)\n","        return logits\n"],"metadata":{"id":"XjT1C2Tx08dT","executionInfo":{"status":"ok","timestamp":1766237755788,"user_tz":-60,"elapsed":13,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["MNIST_DIR = \"/content/drive/MyDrive/AIProject/numbers\"\n","train_images_path = f\"{MNIST_DIR}/train-images.idx3-ubyte\"\n","train_labels_path = f\"{MNIST_DIR}/train-labels.idx1-ubyte\"\n","test_images_path = f\"{MNIST_DIR}/t10k-images.idx3-ubyte\"\n","test_labels_path = f\"{MNIST_DIR}/t10k-labels.idx1-ubyte\"\n","\n","X_mnist_train = idx2numpy.convert_from_file(train_images_path)\n","y_mnist_train = idx2numpy.convert_from_file(train_labels_path)\n","X_mnist_test  = idx2numpy.convert_from_file(test_images_path)\n","y_mnist_test  = idx2numpy.convert_from_file(test_labels_path)\n","\n","# normalize to (0, 1)\n","X_mnist_train = X_mnist_train.astype(np.float32) / 255.0\n","X_mnist_test = X_mnist_test.astype(np.float32)  / 255.0\n","\n","# add channel dimension: (N, 28, 28) -> (N, 1, 28, 28)\n","if X_mnist_train.ndim == 3:\n","    X_mnist_train = X_mnist_train[:, None, :, :]\n","if X_mnist_test.ndim == 3:\n","    X_mnist_test  = X_mnist_test[:, None, :, :]\n","\n","print(\"MNIST shapes:\", X_mnist_train.shape, X_mnist_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzEQeBU92p5X","executionInfo":{"status":"ok","timestamp":1766237758553,"user_tz":-60,"elapsed":455,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"f00d3e11-965c-406f-ff70-0d33d2f6cdd7"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["MNIST shapes: (60000, 1, 28, 28) (10000, 1, 28, 28)\n"]}]},{"cell_type":"code","source":["X_digits = np.concatenate([X_mnist_train, X_mnist_test], axis=0)\n","y_digits = np.concatenate([y_mnist_train, y_mnist_test], axis=0)  # 0–9\n","\n","X_digits_tensor = torch.from_numpy(X_digits)\n","y_digits_tensor = torch.from_numpy(y_digits)\n","\n","digit_dataset = TensorDataset(X_digits_tensor, y_digits_tensor)\n","\n","total_len = len(digit_dataset)\n","train_len = int(0.8 * total_len)\n","val_len = int(0.1 * total_len)\n","test_len = total_len - train_len - val_len\n","\n","digit_train_ds, digit_val_ds, digit_test_ds = random_split(\n","    digit_dataset, [train_len, val_len, test_len],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","\n","BATCH_SIZE = 128\n","digit_train_dl = DataLoader(digit_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","digit_val_dl = DataLoader(digit_val_ds, batch_size=BATCH_SIZE, shuffle=False)\n","digit_test_dl = DataLoader(digit_test_ds, batch_size=BATCH_SIZE, shuffle=False)\n"],"metadata":{"id":"VZ9rSDKT2YCU","executionInfo":{"status":"ok","timestamp":1766237759569,"user_tz":-60,"elapsed":3,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["digit_model = SimpleLSTM(num_classes=10, hidden_size=128, num_layers=2, bidirectional=True).to(device)\n","digit_criterion = nn.CrossEntropyLoss()\n","digit_optimizer = torch.optim.Adam(digit_model.parameters(), lr=1e-3)\n","\n","EPOCHS = 15\n","for epoch in range(1, EPOCHS + 1):\n","    train_loss, train_acc = train_one_epoch(digit_model, digit_train_dl, digit_optimizer, digit_criterion, device)\n","    val_loss, val_acc = eval_model(digit_model, digit_val_dl, digit_criterion, device)\n","    print(\n","        f\"DIGITS LSTM -> Epoch {epoch}: \"\n","        f\"train loss = {train_loss:.4f}, train accuracy = {train_acc*100:.2f}% | \"\n","        f\"validation loss = {val_loss:.4f}, validation accuracy = {val_acc*100:.2f}%\"\n","    )\n","\n","test_loss, test_acc = eval_model(digit_model, digit_test_dl, digit_criterion, device)\n","print(f\"DIGITS LSTM -> Test loss = {test_loss:.4f}, test accuracy = {test_acc*100:.2f}%\")\n","\n","DIGIT_LSTM_MODEL_PATH = \"/content/drive/MyDrive/AIProject/digit_lstm_10cls.pth\"\n","torch.save(digit_model.state_dict(), DIGIT_LSTM_MODEL_PATH)\n","print(\"Saved digit LSTM model to:\", DIGIT_LSTM_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GExHwvAD0kDg","executionInfo":{"status":"ok","timestamp":1766237884850,"user_tz":-60,"elapsed":70177,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"ce9913ba-151c-42e4-8a26-385614b6a977"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["DIGITS LSTM -> Epoch 1: train loss = 0.5730, train accuracy = 80.92% | validation loss = 0.1908, validation accuracy = 94.25%\n","DIGITS LSTM -> Epoch 2: train loss = 0.1457, train accuracy = 95.49% | validation loss = 0.1437, validation accuracy = 95.24%\n","DIGITS LSTM -> Epoch 3: train loss = 0.0984, train accuracy = 96.95% | validation loss = 0.0870, validation accuracy = 97.52%\n","DIGITS LSTM -> Epoch 4: train loss = 0.0682, train accuracy = 97.91% | validation loss = 0.0649, validation accuracy = 98.23%\n","DIGITS LSTM -> Epoch 5: train loss = 0.0554, train accuracy = 98.27% | validation loss = 0.0646, validation accuracy = 98.20%\n","DIGITS LSTM -> Epoch 6: train loss = 0.0491, train accuracy = 98.47% | validation loss = 0.0569, validation accuracy = 98.27%\n","DIGITS LSTM -> Epoch 7: train loss = 0.0412, train accuracy = 98.73% | validation loss = 0.0625, validation accuracy = 98.20%\n","DIGITS LSTM -> Epoch 8: train loss = 0.0358, train accuracy = 98.89% | validation loss = 0.0649, validation accuracy = 98.07%\n","DIGITS LSTM -> Epoch 9: train loss = 0.0333, train accuracy = 98.97% | validation loss = 0.0531, validation accuracy = 98.44%\n","DIGITS LSTM -> Epoch 10: train loss = 0.0274, train accuracy = 99.15% | validation loss = 0.0648, validation accuracy = 98.15%\n","DIGITS LSTM -> Epoch 11: train loss = 0.0266, train accuracy = 99.16% | validation loss = 0.0430, validation accuracy = 98.71%\n","DIGITS LSTM -> Epoch 12: train loss = 0.0200, train accuracy = 99.37% | validation loss = 0.0487, validation accuracy = 98.67%\n","DIGITS LSTM -> Epoch 13: train loss = 0.0213, train accuracy = 99.33% | validation loss = 0.0530, validation accuracy = 98.41%\n","DIGITS LSTM -> Epoch 14: train loss = 0.0195, train accuracy = 99.38% | validation loss = 0.0467, validation accuracy = 98.67%\n","DIGITS LSTM -> Epoch 15: train loss = 0.0170, train accuracy = 99.49% | validation loss = 0.0402, validation accuracy = 98.81%\n","DIGITS LSTM -> Test loss = 0.0431, test accuracy = 98.80%\n","Saved digit LSTM model to: /content/drive/MyDrive/AIProject/digit_lstm_10cls.pth\n"]}]},{"cell_type":"code","source":["AZ_DIR = \"/content/drive/MyDrive/AIProject/letters kaggle\"\n","AZ_CSV = f\"{AZ_DIR}/A_Z Handwritten Data.csv\"\n","\n","az_df = pd.read_csv(AZ_CSV, header=None)  # Kaggle A_Z CSV: first column is label, next 784 columns are pixels\n","\n","# labels: 0–25 for A–Z\n","y_az = az_df.iloc[:, 0].values.astype(np.int64)\n","\n","# pixels\n","X_az = az_df.iloc[:, 1:].values.astype(np.float32)\n","\n","# normalize to (0, 1)\n","X_az /= 255.0\n","\n","# reshape to (N, 1, 28, 28)\n","X_az = X_az.reshape(-1, 1, 28, 28)\n","print(\"A_Z shapes:\", X_az.shape, y_az.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K23RxJHw3c8v","executionInfo":{"status":"ok","timestamp":1766237923431,"user_tz":-60,"elapsed":27145,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"c76155de-5a36-43d1-a443-05b53870326b"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["A_Z shapes: (372451, 1, 28, 28) (372451,)\n"]}]},{"cell_type":"code","source":["X_letters_tensor = torch.from_numpy(X_az)\n","y_letters_tensor = torch.from_numpy(y_az)\n","\n","letter_dataset = TensorDataset(X_letters_tensor, y_letters_tensor)\n","\n","total_len = len(letter_dataset)\n","train_len = int(0.8 * total_len)\n","val_len = int(0.1 * total_len)\n","test_len = total_len - train_len - val_len\n","\n","letter_train_ds, letter_val_ds, letter_test_ds = random_split(\n","    letter_dataset, [train_len, val_len, test_len],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","\n","BATCH_SIZE = 128\n","letter_train_dl = DataLoader(letter_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","letter_val_dl = DataLoader(letter_val_ds, batch_size=BATCH_SIZE, shuffle=False)\n","letter_test_dl = DataLoader(letter_test_ds, batch_size=BATCH_SIZE, shuffle=False)\n"],"metadata":{"id":"zP3FLCrh3hJ8","executionInfo":{"status":"ok","timestamp":1766237961394,"user_tz":-60,"elapsed":81,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["letter_model = SimpleLSTM(num_classes=26, hidden_size=128, num_layers=2, bidirectional=True).to(device)\n","letter_criterion = nn.CrossEntropyLoss()\n","letter_optimizer = torch.optim.Adam(letter_model.parameters(), lr=1e-3)\n","\n","EPOCHS = 15\n","for epoch in range(1, EPOCHS + 1):\n","    train_loss, train_acc = train_one_epoch(letter_model, letter_train_dl, letter_optimizer, letter_criterion, device)\n","    val_loss, val_acc = eval_model(letter_model, letter_val_dl, letter_criterion, device)\n","    print(\n","        f\"LETTERS LSTM -> Epoch {epoch}: \"\n","        f\"train loss = {train_loss:.4f}, train accuracy = {train_acc*100:.2f}% | \"\n","        f\"validation loss = {val_loss:.4f}, validation accuracy = {val_acc*100:.2f}%\"\n","    )\n","\n","test_loss, test_acc = eval_model(letter_model, letter_test_dl, letter_criterion, device)\n","print(f\"LETTERS LSTM -> Test loss = {test_loss:.4f}, test accuracy = {test_acc*100:.2f}%\")\n","\n","LETTER_LSTM_MODEL_PATH = \"/content/drive/MyDrive/AIProject/letter_lstm_26cls.pth\"\n","torch.save(letter_model.state_dict(), LETTER_LSTM_MODEL_PATH)\n","print(\"Saved letter LSTM model to:\", LETTER_LSTM_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-aRfDsY0nZv","executionInfo":{"status":"ok","timestamp":1766238397443,"user_tz":-60,"elapsed":429365,"user":{"displayName":"Cherry None","userId":"12191178377710756432"}},"outputId":"f73aa67d-7342-4ecd-b766-07d96c7620a3"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["LETTERS LSTM -> Epoch 1: train loss = 0.4090, train accuracy = 87.99% | validation loss = 0.1325, validation accuracy = 96.26%\n","LETTERS LSTM -> Epoch 2: train loss = 0.1001, train accuracy = 97.12% | validation loss = 0.0843, validation accuracy = 97.59%\n","LETTERS LSTM -> Epoch 3: train loss = 0.0746, train accuracy = 97.84% | validation loss = 0.0688, validation accuracy = 98.02%\n","LETTERS LSTM -> Epoch 4: train loss = 0.0584, train accuracy = 98.29% | validation loss = 0.0538, validation accuracy = 98.46%\n","LETTERS LSTM -> Epoch 5: train loss = 0.0482, train accuracy = 98.58% | validation loss = 0.0492, validation accuracy = 98.59%\n","LETTERS LSTM -> Epoch 6: train loss = 0.0417, train accuracy = 98.73% | validation loss = 0.0544, validation accuracy = 98.42%\n","LETTERS LSTM -> Epoch 7: train loss = 0.0353, train accuracy = 98.91% | validation loss = 0.0456, validation accuracy = 98.72%\n","LETTERS LSTM -> Epoch 8: train loss = 0.0306, train accuracy = 99.07% | validation loss = 0.0498, validation accuracy = 98.53%\n","LETTERS LSTM -> Epoch 9: train loss = 0.0269, train accuracy = 99.15% | validation loss = 0.0408, validation accuracy = 98.83%\n","LETTERS LSTM -> Epoch 10: train loss = 0.0236, train accuracy = 99.25% | validation loss = 0.0369, validation accuracy = 98.99%\n","LETTERS LSTM -> Epoch 11: train loss = 0.0213, train accuracy = 99.31% | validation loss = 0.0371, validation accuracy = 98.99%\n","LETTERS LSTM -> Epoch 12: train loss = 0.0191, train accuracy = 99.39% | validation loss = 0.0327, validation accuracy = 99.09%\n","LETTERS LSTM -> Epoch 13: train loss = 0.0174, train accuracy = 99.43% | validation loss = 0.0339, validation accuracy = 99.06%\n","LETTERS LSTM -> Epoch 14: train loss = 0.0158, train accuracy = 99.50% | validation loss = 0.0354, validation accuracy = 99.09%\n","LETTERS LSTM -> Epoch 15: train loss = 0.0140, train accuracy = 99.54% | validation loss = 0.0393, validation accuracy = 98.97%\n","LETTERS LSTM -> Test loss = 0.0405, test accuracy = 98.97%\n","Saved letter LSTM model to: /content/drive/MyDrive/AIProject/letter_lstm_26cls.pth\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vIELooYH3yr3"},"execution_count":null,"outputs":[]}]}