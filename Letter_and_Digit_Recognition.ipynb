{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a34695c9-28dc-46d8-b0b0-9583802a0da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a34695c9-28dc-46d8-b0b0-9583802a0da1",
        "outputId": "c3ac051e-a3f0-4242-db28-08977e6e2c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from idx2numpy) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from idx2numpy) (1.17.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7903 sha256=17f9c061da1d57e81b8843b3c22d6b2b12b48384521cb87833a2c6c45929b03b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/48/00/ae031c97d62f39e1c3c4daa00426c09a65eb29ae5753a189ee\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n",
            "Mounted at /content/drive\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install idx2numpy\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_DIR = \"/content/drive/MyDrive/AIProject/numbers\"\n",
        "print(\"MNIST_DIR:\", MNIST_DIR)\n",
        "print(\"Exists?\", os.path.exists(MNIST_DIR))\n",
        "print(\"Contents:\", os.listdir(MNIST_DIR) if os.path.exists(MNIST_DIR) else \"NO DIR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kAcZqBlYZLZ",
        "outputId": "9bb6aaba-5f52-4f22-8d74-a5c87a479055"
      },
      "id": "-kAcZqBlYZLZ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST_DIR: /content/drive/MyDrive/AIProject/numbers\n",
            "Exists? True\n",
            "Contents: ['t10k-labels.idx1-ubyte', 't10k-images.idx3-ubyte', 'train-images.idx3-ubyte', 'train-labels.idx1-ubyte', 't10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte', 'train-labels-idx1-ubyte', 'train-images-idx3-ubyte']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "573c3e89-f5d5-412d-bcb6-40c8be96f8ae",
      "metadata": {
        "id": "573c3e89-f5d5-412d-bcb6-40c8be96f8ae"
      },
      "outputs": [],
      "source": [
        "# compares predictions to true labels and returns the accuracy\n",
        "def accuracy_from_logits(logits, targets):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    correct = (preds == targets).sum().item()\n",
        "    total = targets.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# loops over each batch of images and labels from train_dl\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_acc  = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc  += accuracy_from_logits(outputs, labels)\n",
        "        total_batches += 1\n",
        "\n",
        "    return running_loss / total_batches, running_acc / total_batches\n",
        "\n",
        "# Loops over all batches in val_dl or test_dl, computes outputs and loss, and averages loss and accuracy\n",
        "def eval_model(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_acc  = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_acc  += accuracy_from_logits(outputs, labels)\n",
        "            total_batches += 1\n",
        "\n",
        "    return running_loss / total_batches, running_acc / total_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "82979e77-a79e-47f0-97f7-6ef3befc96aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82979e77-a79e-47f0-97f7-6ef3befc96aa",
        "outputId": "6f8ace0c-12e0-45cf-ed5e-933ab49b415f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIProject/numbers/train-images.idx3-ubyte\n",
            "/content/drive/MyDrive/AIProject/numbers/t10k-images.idx3-ubyte\n"
          ]
        }
      ],
      "source": [
        "MNIST_DIR = \"/content/drive/MyDrive/AIProject/numbers\"\n",
        "\n",
        "train_images_path = f\"{MNIST_DIR}/train-images.idx3-ubyte\"\n",
        "train_labels_path = f\"{MNIST_DIR}/train-labels.idx1-ubyte\"\n",
        "test_images_path  = f\"{MNIST_DIR}/t10k-images.idx3-ubyte\"\n",
        "test_labels_path  = f\"{MNIST_DIR}/t10k-labels.idx1-ubyte\"\n",
        "\n",
        "print(train_images_path)\n",
        "print(test_images_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95675dcc-ef10-4192-b5d1-88f6d5c9d00e",
      "metadata": {
        "id": "95675dcc-ef10-4192-b5d1-88f6d5c9d00e"
      },
      "outputs": [],
      "source": [
        "import idx2numpy\n",
        "import numpy as np\n",
        "\n",
        "X_mnist_train = idx2numpy.convert_from_file(train_images_path)\n",
        "y_mnist_train = idx2numpy.convert_from_file(train_labels_path)\n",
        "X_mnist_test  = idx2numpy.convert_from_file(test_images_path)\n",
        "y_mnist_test  = idx2numpy.convert_from_file(test_labels_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3075ccc0-4db6-4a5c-ad96-98e2269b9342",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3075ccc0-4db6-4a5c-ad96-98e2269b9342",
        "outputId": "361bcc8a-7d43-496f-fdbc-6a62fdc310c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(372451, 1, 28, 28) 10 35\n"
          ]
        }
      ],
      "source": [
        "AZ_DIR = \"/content/drive/MyDrive/AIProject/letters kaggle\"\n",
        "AZ_CSV = f\"{AZ_DIR}/A_Z Handwritten Data.csv\"\n",
        "az_df = pd.read_csv(AZ_CSV, header=None)\n",
        "y_az = az_df.iloc[:, 0].values.astype(np.int64)      # 0–25 (A–Z) corresponds to letter position in alphabet\n",
        "X_az = az_df.iloc[:, 1:].values.astype(np.float32)   # 784 pixels in float format\n",
        "\n",
        "X_az /= 255.0   # scales pixel values from 0–255 to 0–1\n",
        "X_az = X_az.reshape(-1, 1, 28, 28)   # turns each row of 784 numbers into a 28×28 grayscale image with 1 channel\n",
        "\n",
        "# 0-9 for digits, 10-35 for letters\n",
        "y_az_shifted = y_az + 10  # letters -> 10..35\n",
        "print(X_az.shape, y_az_shifted.min(), y_az_shifted.max())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_mnist_train:\", X_mnist_train.shape)\n",
        "print(\"X_mnist_test:\",  X_mnist_test.shape)\n",
        "print(\"X_az:\",          X_az.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27lrX3r2bIIK",
        "outputId": "54462093-7589-4a68-a8ca-43a71cc4d4bb"
      },
      "id": "27lrX3r2bIIK",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_mnist_train: (60000, 28, 28)\n",
            "X_mnist_test: (10000, 28, 28)\n",
            "X_az: (372451, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if they are (N, 28, 28), add channel dimension\n",
        "if X_mnist_train.ndim == 3:\n",
        "    X_mnist_train = X_mnist_train[:, None, :, :]\n",
        "if X_mnist_test.ndim == 3:\n",
        "    X_mnist_test  = X_mnist_test[:, None, :, :]\n",
        "\n",
        "print(\"X_mnist_train:\", X_mnist_train.shape)  # should be (N, 1, 28, 28)\n",
        "print(\"X_mnist_test:\",  X_mnist_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL_mzs2dbMfv",
        "outputId": "c1252d52-d78b-41e0-86ab-24c202b4196d"
      },
      "id": "uL_mzs2dbMfv",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_mnist_train: (60000, 1, 28, 28)\n",
            "X_mnist_test: (10000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after reading A_Z CSV and normalizing:\n",
        "X_az = X_az.reshape(-1, 1, 28, 28)\n",
        "print(\"X_az:\", X_az.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqHxy65AbRAC",
        "outputId": "f960321e-bfd9-4ac5-ffbe-d932faaf8473"
      },
      "id": "OqHxy65AbRAC",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_az: (372451, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "db3c207f-e45b-4d1e-a850-7cdf374a3557",
      "metadata": {
        "id": "db3c207f-e45b-4d1e-a850-7cdf374a3557"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# combine MNIST train+test\n",
        "X_digits = np.concatenate([X_mnist_train, X_mnist_test], axis=0)\n",
        "y_digits = np.concatenate([y_mnist_train, y_mnist_test], axis=0)\n",
        "\n",
        "X_all = np.concatenate([X_digits, X_az], axis=0)\n",
        "y_all = np.concatenate([y_digits, y_az_shifted], axis=0)\n",
        "\n",
        "X_all_tensor = torch.from_numpy(X_all)\n",
        "y_all_tensor = torch.from_numpy(y_all)\n",
        "\n",
        "dataset = TensorDataset(X_all_tensor, y_all_tensor)\n",
        "\n",
        "total_len = len(dataset)\n",
        "train_len = int(0.8 * total_len)\n",
        "val_len   = int(0.1 * total_len)\n",
        "test_len  = total_len - train_len - val_len\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(\n",
        "    dataset, [train_len, val_len, test_len],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dl  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1d16ed14-297e-4b74-b7ee-cea8086fb478",
      "metadata": {
        "id": "1d16ed14-297e-4b74-b7ee-cea8086fb478"
      },
      "outputs": [],
      "source": [
        "class CharDigitCNN(nn.Module):\n",
        "    def __init__(self, num_classes=36):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool  = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1   = nn.Linear(128 * 7 * 7, 256)\n",
        "        self.fc2   = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = CharDigitCNN(num_classes=36).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5bb30b61-cb8f-4b8a-a651-52e4a866115f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bb30b61-cb8f-4b8a-a651-52e4a866115f",
        "outputId": "0939e755-4978-4f19-a429-d977340bf1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: train_loss=0.2912, train_acc=91.88% | val_loss=0.0932, val_acc=97.41%\n",
            "Epoch 02: train_loss=0.0749, train_acc=97.93% | val_loss=0.0826, val_acc=97.70%\n",
            "Epoch 03: train_loss=0.0564, train_acc=98.45% | val_loss=0.0576, val_acc=98.44%\n",
            "Epoch 04: train_loss=0.0445, train_acc=98.75% | val_loss=0.0549, val_acc=98.45%\n",
            "Epoch 05: train_loss=0.0372, train_acc=98.94% | val_loss=0.0504, val_acc=98.54%\n",
            "Epoch 06: train_loss=0.0314, train_acc=99.11% | val_loss=0.0442, val_acc=98.87%\n",
            "Epoch 07: train_loss=0.0267, train_acc=99.24% | val_loss=0.0480, val_acc=98.86%\n",
            "Epoch 08: train_loss=0.0233, train_acc=99.33% | val_loss=0.0468, val_acc=99.00%\n",
            "Epoch 09: train_loss=0.0208, train_acc=99.41% | val_loss=0.0404, val_acc=99.01%\n",
            "Epoch 10: train_loss=0.0195, train_acc=99.46% | val_loss=0.0431, val_acc=98.97%\n",
            "Epoch 11: train_loss=0.0164, train_acc=99.54% | val_loss=0.0466, val_acc=98.98%\n",
            "Epoch 12: train_loss=0.0165, train_acc=99.56% | val_loss=0.0442, val_acc=99.06%\n",
            "Epoch 13: train_loss=0.0148, train_acc=99.59% | val_loss=0.0480, val_acc=99.17%\n",
            "Epoch 14: train_loss=0.0145, train_acc=99.62% | val_loss=0.0442, val_acc=99.20%\n",
            "Epoch 15: train_loss=0.0136, train_acc=99.65% | val_loss=0.0661, val_acc=99.13%\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 15\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_dl, optimizer, criterion, device)\n",
        "    val_loss, val_acc     = eval_model(model, val_dl, criterion, device)\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d}: \"\n",
        "        f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "        f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5326307f-a838-4379-b70b-f3e11c735bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5326307f-a838-4379-b70b-f3e11c735bdf",
        "outputId": "c1caf9f6-114c-4530-ba86-bb26addb54dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss=0.0669, test acc=99.16%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = eval_model(model, test_dl, criterion, device)\n",
        "print(f\"Test loss={test_loss:.4f}, test acc={test_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be49046-4529-44dc-b0c9-5aae630de0c7",
      "metadata": {
        "id": "3be49046-4529-44dc-b0c9-5aae630de0c7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}